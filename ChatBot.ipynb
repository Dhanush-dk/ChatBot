{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tflearn","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting tflearn\n  Downloading tflearn-0.5.0.tar.gz (107 kB)\n\u001b[K     |████████████████████████████████| 107 kB 1.3 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from tflearn) (1.18.5)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from tflearn) (1.14.0)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.7/site-packages (from tflearn) (8.0.1)\nBuilding wheels for collected packages: tflearn\n  Building wheel for tflearn (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127300 sha256=342ae2168ba2067f04f0a7b4711be3b15be39c92d0a6dc21f0481db79d43e1f6\n  Stored in directory: /root/.cache/pip/wheels/5f/14/2e/1d8e28cc47a5a931a2fb82438c9e37ef9246cc6a3774520271\nSuccessfully built tflearn\nInstalling collected packages: tflearn\nSuccessfully installed tflearn-0.5.0\n\u001b[33mWARNING: You are using pip version 20.3.1; however, version 20.3.3 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import nltk\nnltk.download('punkt')\nfrom nltk.stem.lancaster import LancasterStemmer\nstemmer = LancasterStemmer()","execution_count":2,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy\nimport tflearn\nimport tensorflow\nimport random\nimport json\nimport pickle","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(\"../input/intents-for-first-aid-recommendations/intents.json\") as file:\n\tdata = json.load(file)","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nwords = []\nlabels = []\ndocs_x = []\ndocs_y = []\n\nfor intent in data[\"intents\"]:\n\tfor pattern in intent[\"patterns\"]:\n\t\twrds = nltk.word_tokenize(pattern)\n\t\twords.extend(wrds)\n\t\tdocs_x.append(wrds)\n\t\tdocs_y.append(intent[\"tag\"])\n\n\tif intent[\"tag\"] not in labels:\n\t\tlabels.append(intent[\"tag\"])\n\nwords = [stemmer.stem(w.lower()) for w in words if w != \"?\"]\nwords = sorted(list(set(words)))\n\nlabels = sorted(labels)\n\n\ntraining = []\noutput = []\n\nout_empty = [0 for _ in range(len(labels))]\n\nfor x, doc in enumerate(docs_x):\n\tbag = []\n\n\twrds = [stemmer.stem(w) for w in doc]\n\n\tfor w in words:\n\t\tif w in wrds:\n\t\t\tbag.append(1)\n\t\telse:\n\t\t\tbag.append(0)\n\toutput_row = out_empty[:]\n\toutput_row[labels.index(docs_y[x])] = 1\n\n\ttraining.append(bag)\n\toutput.append(output_row)\n\ntraining = numpy.array(training)\noutput = numpy.array(output)\n","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tensorflow.compat.v1.reset_default_graph()\n\nnet = tflearn.input_data(shape=[None, len(training[0])])\nnet = tflearn.fully_connected(net, 8)\nnet = tflearn.fully_connected(net, 8)\nnet = tflearn.fully_connected(net, len(output[0]), activation=\"softmax\")\nnet = tflearn.regression(net)\n\nmodel = tflearn.DNN(net)","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n\tmodel.load(\"model.tflearn\")\nexcept:\n\tmodel = tflearn.DNN(net)\n\tmodel.fit(training, output, n_epoch=1000, batch_size=8, show_metric=True)\n\tmodel.save(\"model.tflearn\")","execution_count":7,"outputs":[{"output_type":"stream","text":"Training Step: 23999  | time: 0.101s\n| Adam | epoch: 1000 | loss: 0.00000 - acc: 0.9962 -- iter: 184/188\nTraining Step: 24000  | time: 0.106s\n| Adam | epoch: 1000 | loss: 0.00000 - acc: 0.9966 -- iter: 188/188\n--\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bag_of_words(s,words):\n\tbag = [0 for _ in range(len(words))]\n\n\n\ts_words = nltk.word_tokenize(s)\n\ts_words = [stemmer.stem(word.lower()) for word in s_words]\n\n\tfor se in s_words:\n\t\tfor i, w in enumerate(words):\n\t\t\tif w == se:\n\t\t\t\tbag[i] = 1\n\n\treturn numpy.array(bag)","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def chat():\n\tprint(\"Start Talking with the bot(type quit to stop!\")\n\twhile True:\n\t\tinp = input(\"You: \")\n\t\tif inp.lower() == \"quit\":\n\t\t\tbreak\n\n\t\tresults = model.predict([bag_of_words(inp,words)])[0]\n\t\tresults_index = numpy.argmax(results)\n\t\ttag = labels[results_index]\n\n\t\tif results[results_index] > 0.5:\n\t\t\tfor tg in data[\"intents\"]:\n\t\t\t\tif tg['tag'] == tag:\n\t\t\t\t\tresponses = tg['responses']\n\t\t\tprint(random.choice(responses))\n\t\t\tprint(\"\\n\")\n\n\t\telse:\n\t\t\tprint(\"I didnt get that, try again\")","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chat() ","execution_count":null,"outputs":[{"output_type":"stream","text":"Start Talking with the bot(type quit to stop!\nYou: What to do if i got a cut?\nWash the cut properly to prevent infection and stop the bleeding by applying pressure for 1-2minutes until bleeding stops. Apply Petroleum Jelly to make sure that the wound is moist for quick healing. Finally cover the cut with a sterile bandage. Pain relievers such as acetaminophen can be applied.\n\n\n","name":"stdout"}]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}